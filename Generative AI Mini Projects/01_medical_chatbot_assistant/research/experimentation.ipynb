{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "\n",
    "# **Medical Chatbot Assistant**\n",
    "\n",
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Import Libraries**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\Medical Chatbot\\.venv\\lib\\site-packages\\pinecone\\data\\index.py:1: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from tqdm.autonotebook import tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from langchain_community.document_loaders import PyPDFLoader, DirectoryLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "from pinecone import Pinecone, ServerlessSpec\n",
    "from langchain_pinecone import PineconeVectorStore"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Set up Environment Variables**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "os.environ['OPENAI_API_KEY'] = os.getenv('OPENAI_API_KEY')\n",
    "os.environ['HF_TOKEN'] = os.getenv('HF_TOKEN')\n",
    "api_key = os.getenv(\"PINECONE_API_KEY\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Load Data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_pdf_file(directory_path):\n",
    "    # Create a DirectoryLoader instance to load PDF files from the specified directory.\n",
    "    loader = DirectoryLoader(directory_path, \n",
    "                             glob=\"*.pdf\",  # Specify that we want to load files with a .pdf extension\n",
    "                             loader_cls=PyPDFLoader)  # Use PyPDFLoader to handle the loading of PDF files\n",
    "    \n",
    "    # Load the documents (PDF files) using the loader\n",
    "    documents = loader.load()\n",
    "    \n",
    "    # Return the loaded documents\n",
    "    return documents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- This book consist of more than 700 pages so it is going to take some time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "directory_path = r\"E:\\Medical Chatbot\\data\"\n",
    "\n",
    "extracted_data = load_pdf_file(directory_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Split the Data Into Chunks**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_split(extracted_data):\n",
    "    # Create an instance of RecursiveCharacterTextSplitter to split text into manageable chunks.\n",
    "    text_splitter = RecursiveCharacterTextSplitter(\n",
    "        chunk_size=500,    # Set the maximum size of each chunk to 500 characters\n",
    "        chunk_overlap=20,   # Allow an overlap of 20 characters between consecutive chunks\n",
    "    )\n",
    "    \n",
    "    # Split the extracted data into text chunks using the defined splitter\n",
    "    text_chunks = text_splitter.split_documents(extracted_data)\n",
    "    \n",
    "    # Return the list of text chunks\n",
    "    return text_chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of the Chunks: 7020\n"
     ]
    }
   ],
   "source": [
    "text_chunks = text_split(extracted_data)\n",
    "print(f\"Length of the Chunks: {len(text_chunks)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Load Embedding Model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_huggingface_embedding():\n",
    "    # Create an instance of the updated HuggingFaceEmbeddings class.\n",
    "    embedding = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")\n",
    "    return embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding = download_huggingface_embedding()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "HuggingFaceEmbeddings(client=SentenceTransformer(\n",
       "  (0): Transformer({'max_seq_length': 256, 'do_lower_case': False}) with Transformer model: BertModel \n",
       "  (1): Pooling({'word_embedding_dimension': 384, 'pooling_mode_cls_token': False, 'pooling_mode_mean_tokens': True, 'pooling_mode_max_tokens': False, 'pooling_mode_mean_sqrt_len_tokens': False, 'pooling_mode_weightedmean_tokens': False, 'pooling_mode_lasttoken': False, 'include_prompt': True})\n",
       "  (2): Normalize()\n",
       "), model_name='sentence-transformers/all-MiniLM-L6-v2', cache_folder=None, model_kwargs={}, encode_kwargs={}, multi_process=False, show_progress=False)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Let's Try to Convert A sentence into embedding**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Length of Embeddings is 384.\n"
     ]
    }
   ],
   "source": [
    "querry_result = embedding.embed_query(\"Hello World\")\n",
    "print(f\"The Length of Embeddings is {len(querry_result)}.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Setup Pinecone Vector DB**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the name of the index to be used for the Pinecone vector database.\n",
    "index_name = \"medical-chatbot-implementation\"\n",
    "\n",
    "# Initialize a Pinecone client using the provided API key.\n",
    "pc = Pinecone(api_key=api_key)\n",
    "\n",
    "# Check if the specified index already exists in the Pinecone environment.\n",
    "if index_name not in pc.list_indexes().names():\n",
    "    # If the index does not exist, create a new index with the specified parameters.\n",
    "    pc.create_index(\n",
    "        name=index_name,            # Set the name of the index\n",
    "        dimension=384,              # Specify the dimensionality of the vectors stored in the index\n",
    "        metric=\"cosine\",            # Use cosine similarity as the distance metric\n",
    "        spec=ServerlessSpec(        # Define the serverless specification for the index\n",
    "            cloud=\"aws\",            # Specify the cloud provider\n",
    "            region=\"us-east-1\"      # Specify the region for the index\n",
    "        )\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Upsert Embeddings in Pinecone**\n",
    "\n",
    "- Embed each chunk and upsert the embeddings into your Pinecone index."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a PineconeVectorStore instance from the provided documents and embedding model.\n",
    "docsearch = PineconeVectorStore.from_documents(\n",
    "    documents=text_chunks,  # The list of text chunks to be stored in the vector store.\n",
    "    index_name=index_name,  # The name of the index where the vectors will be stored.\n",
    "    embedding=embedding,     # The embedding model used to convert documents into vector representations.\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def batch_upsert(index, text_chunks, embedding, batch_size=100):\n",
    "#     # Iterate over the embeddings in batches of specified size.\n",
    "#     for i in tqdm(range(0, len(embedding), batch_size)):\n",
    "#         # Determine the end index for the current batch.\n",
    "#         i_end = min(i + batch_size, len(embedding))\n",
    "        \n",
    "#         # Create a batch of tuples containing the ID, embedding vector, and associated text.\n",
    "#         batch = list(zip(\n",
    "#             [str(j) for j in range(i, i_end)],  # Generate a list of string IDs for each embedding\n",
    "#             embedding[i:i_end],                 # Get the current batch of embedding vectors\n",
    "#             [{\"text\": chunk.page_content} for chunk in text_chunks[i:i_end]]  # Extract the text content for each chunk\n",
    "#         ))\n",
    "        \n",
    "#         # Upsert (update or insert) the batch of vectors into the specified index.\n",
    "#         index.upsert(vectors=batch)\n",
    "\n",
    "# # Initialize the index using the specified index name.\n",
    "# index = pc.Index(index_name)\n",
    "\n",
    "# # Call the batch_upsert function to insert the text chunks and their embeddings into the index.\n",
    "# batch_upsert(index, text_chunks, embeddings_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Create a PineconeVectorStore instance using an existing index**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "docsearch = PineconeVectorStore.from_existing_index(\n",
    "    index_name=index_name,  # The name of the existing index to connect to.\n",
    "    embedding=embedding,     # The embedding model used to convert documents into vector representations.\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
