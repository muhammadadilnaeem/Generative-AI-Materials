{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PtkvR5XNBE82"
      },
      "source": [
        "\n",
        "-----\n",
        "\n",
        "# **Chromadb Vector Database**\n",
        "\n",
        "```python\n",
        "!pip install chromadb openai langchain langchain_openai langchain_community tiktoken\n",
        "```\n",
        "\n",
        "-----"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d1cfSiaj06eE"
      },
      "source": [
        "### **1. Install Chromadb and other Dependencies**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7uWQyZvnBcf0",
        "outputId": "e16f7fb4-a374-480d-f229-739bab0f556d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: chromadb in /usr/local/lib/python3.10/dist-packages (0.5.13)\n",
            "Requirement already satisfied: openai in /usr/local/lib/python3.10/dist-packages (1.51.2)\n",
            "Requirement already satisfied: langchain in /usr/local/lib/python3.10/dist-packages (0.3.3)\n",
            "Collecting langchain_openai\n",
            "  Downloading langchain_openai-0.2.2-py3-none-any.whl.metadata (2.6 kB)\n",
            "Requirement already satisfied: langchain_community in /usr/local/lib/python3.10/dist-packages (0.3.2)\n",
            "Requirement already satisfied: tiktoken in /usr/local/lib/python3.10/dist-packages (0.8.0)\n",
            "Requirement already satisfied: build>=1.0.3 in /usr/local/lib/python3.10/dist-packages (from chromadb) (1.2.2.post1)\n",
            "Requirement already satisfied: pydantic>=1.9 in /usr/local/lib/python3.10/dist-packages (from chromadb) (2.9.2)\n",
            "Requirement already satisfied: chroma-hnswlib==0.7.6 in /usr/local/lib/python3.10/dist-packages (from chromadb) (0.7.6)\n",
            "Requirement already satisfied: fastapi>=0.95.2 in /usr/local/lib/python3.10/dist-packages (from chromadb) (0.115.2)\n",
            "Requirement already satisfied: uvicorn>=0.18.3 in /usr/local/lib/python3.10/dist-packages (from uvicorn[standard]>=0.18.3->chromadb) (0.31.1)\n",
            "Requirement already satisfied: numpy>=1.22.5 in /usr/local/lib/python3.10/dist-packages (from chromadb) (1.26.4)\n",
            "Requirement already satisfied: posthog>=2.4.0 in /usr/local/lib/python3.10/dist-packages (from chromadb) (3.7.0)\n",
            "Requirement already satisfied: typing-extensions>=4.5.0 in /usr/local/lib/python3.10/dist-packages (from chromadb) (4.12.2)\n",
            "Requirement already satisfied: onnxruntime>=1.14.1 in /usr/local/lib/python3.10/dist-packages (from chromadb) (1.19.2)\n",
            "Requirement already satisfied: opentelemetry-api>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from chromadb) (1.27.0)\n",
            "Requirement already satisfied: opentelemetry-exporter-otlp-proto-grpc>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from chromadb) (1.27.0)\n",
            "Requirement already satisfied: opentelemetry-instrumentation-fastapi>=0.41b0 in /usr/local/lib/python3.10/dist-packages (from chromadb) (0.48b0)\n",
            "Requirement already satisfied: opentelemetry-sdk>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from chromadb) (1.27.0)\n",
            "Requirement already satisfied: tokenizers>=0.13.2 in /usr/local/lib/python3.10/dist-packages (from chromadb) (0.19.1)\n",
            "Requirement already satisfied: pypika>=0.48.9 in /usr/local/lib/python3.10/dist-packages (from chromadb) (0.48.9)\n",
            "Requirement already satisfied: tqdm>=4.65.0 in /usr/local/lib/python3.10/dist-packages (from chromadb) (4.66.5)\n",
            "Requirement already satisfied: overrides>=7.3.1 in /usr/local/lib/python3.10/dist-packages (from chromadb) (7.7.0)\n",
            "Requirement already satisfied: importlib-resources in /usr/local/lib/python3.10/dist-packages (from chromadb) (6.4.5)\n",
            "Requirement already satisfied: grpcio>=1.58.0 in /usr/local/lib/python3.10/dist-packages (from chromadb) (1.64.1)\n",
            "Requirement already satisfied: bcrypt>=4.0.1 in /usr/local/lib/python3.10/dist-packages (from chromadb) (4.2.0)\n",
            "Requirement already satisfied: typer>=0.9.0 in /usr/local/lib/python3.10/dist-packages (from chromadb) (0.12.5)\n",
            "Requirement already satisfied: kubernetes>=28.1.0 in /usr/local/lib/python3.10/dist-packages (from chromadb) (31.0.0)\n",
            "Requirement already satisfied: tenacity>=8.2.3 in /usr/local/lib/python3.10/dist-packages (from chromadb) (8.5.0)\n",
            "Requirement already satisfied: PyYAML>=6.0.0 in /usr/local/lib/python3.10/dist-packages (from chromadb) (6.0.2)\n",
            "Requirement already satisfied: mmh3>=4.0.1 in /usr/local/lib/python3.10/dist-packages (from chromadb) (5.0.1)\n",
            "Requirement already satisfied: orjson>=3.9.12 in /usr/local/lib/python3.10/dist-packages (from chromadb) (3.10.7)\n",
            "Requirement already satisfied: httpx>=0.27.0 in /usr/local/lib/python3.10/dist-packages (from chromadb) (0.27.2)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.10/dist-packages (from chromadb) (13.9.2)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from openai) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from openai) (1.7.0)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from openai) (0.6.1)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from openai) (1.3.1)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.0.35)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.10/dist-packages (from langchain) (3.10.9)\n",
            "Requirement already satisfied: async-timeout<5.0.0,>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (4.0.3)\n",
            "Requirement already satisfied: langchain-core<0.4.0,>=0.3.10 in /usr/local/lib/python3.10/dist-packages (from langchain) (0.3.10)\n",
            "Requirement already satisfied: langchain-text-splitters<0.4.0,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (0.3.0)\n",
            "Requirement already satisfied: langsmith<0.2.0,>=0.1.17 in /usr/local/lib/python3.10/dist-packages (from langchain) (0.1.134)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.32.3)\n",
            "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in /usr/local/lib/python3.10/dist-packages (from langchain_community) (0.6.7)\n",
            "Requirement already satisfied: pydantic-settings<3.0.0,>=2.4.0 in /usr/local/lib/python3.10/dist-packages (from langchain_community) (2.5.2)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.10/dist-packages (from tiktoken) (2024.9.11)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (2.4.3)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (24.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.1.0)\n",
            "Requirement already satisfied: yarl<2.0,>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.13.1)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (3.10)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (1.2.2)\n",
            "Requirement already satisfied: packaging>=19.1 in /usr/local/lib/python3.10/dist-packages (from build>=1.0.3->chromadb) (24.1)\n",
            "Requirement already satisfied: pyproject_hooks in /usr/local/lib/python3.10/dist-packages (from build>=1.0.3->chromadb) (1.2.0)\n",
            "Requirement already satisfied: tomli>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from build>=1.0.3->chromadb) (2.0.2)\n",
            "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /usr/local/lib/python3.10/dist-packages (from dataclasses-json<0.7,>=0.5.7->langchain_community) (3.22.0)\n",
            "Requirement already satisfied: typing-inspect<1,>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from dataclasses-json<0.7,>=0.5.7->langchain_community) (0.9.0)\n",
            "Requirement already satisfied: starlette<0.41.0,>=0.37.2 in /usr/local/lib/python3.10/dist-packages (from fastapi>=0.95.2->chromadb) (0.39.2)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx>=0.27.0->chromadb) (2024.8.30)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx>=0.27.0->chromadb) (1.0.6)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx>=0.27.0->chromadb) (0.14.0)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from kubernetes>=28.1.0->chromadb) (1.16.0)\n",
            "Requirement already satisfied: python-dateutil>=2.5.3 in /usr/local/lib/python3.10/dist-packages (from kubernetes>=28.1.0->chromadb) (2.8.2)\n",
            "Requirement already satisfied: google-auth>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from kubernetes>=28.1.0->chromadb) (2.27.0)\n",
            "Requirement already satisfied: websocket-client!=0.40.0,!=0.41.*,!=0.42.*,>=0.32.0 in /usr/local/lib/python3.10/dist-packages (from kubernetes>=28.1.0->chromadb) (1.8.0)\n",
            "Requirement already satisfied: requests-oauthlib in /usr/local/lib/python3.10/dist-packages (from kubernetes>=28.1.0->chromadb) (1.3.1)\n",
            "Requirement already satisfied: oauthlib>=3.2.2 in /usr/local/lib/python3.10/dist-packages (from kubernetes>=28.1.0->chromadb) (3.2.2)\n",
            "Requirement already satisfied: urllib3>=1.24.2 in /usr/local/lib/python3.10/dist-packages (from kubernetes>=28.1.0->chromadb) (2.2.3)\n",
            "Requirement already satisfied: durationpy>=0.7 in /usr/local/lib/python3.10/dist-packages (from kubernetes>=28.1.0->chromadb) (0.9)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.4.0,>=0.3.10->langchain) (1.33)\n",
            "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.2.0,>=0.1.17->langchain) (1.0.0)\n",
            "Requirement already satisfied: coloredlogs in /usr/local/lib/python3.10/dist-packages (from onnxruntime>=1.14.1->chromadb) (15.0.1)\n",
            "Requirement already satisfied: flatbuffers in /usr/local/lib/python3.10/dist-packages (from onnxruntime>=1.14.1->chromadb) (24.3.25)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.10/dist-packages (from onnxruntime>=1.14.1->chromadb) (3.20.3)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from onnxruntime>=1.14.1->chromadb) (1.13.3)\n",
            "Requirement already satisfied: deprecated>=1.2.6 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-api>=1.2.0->chromadb) (1.2.14)\n",
            "Requirement already satisfied: importlib-metadata<=8.4.0,>=6.0 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-api>=1.2.0->chromadb) (8.4.0)\n",
            "Requirement already satisfied: googleapis-common-protos~=1.52 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb) (1.65.0)\n",
            "Requirement already satisfied: opentelemetry-exporter-otlp-proto-common==1.27.0 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb) (1.27.0)\n",
            "Requirement already satisfied: opentelemetry-proto==1.27.0 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb) (1.27.0)\n",
            "Requirement already satisfied: opentelemetry-instrumentation-asgi==0.48b0 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb) (0.48b0)\n",
            "Requirement already satisfied: opentelemetry-instrumentation==0.48b0 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb) (0.48b0)\n",
            "Requirement already satisfied: opentelemetry-semantic-conventions==0.48b0 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb) (0.48b0)\n",
            "Requirement already satisfied: opentelemetry-util-http==0.48b0 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb) (0.48b0)\n",
            "Requirement already satisfied: setuptools>=16.0 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-instrumentation==0.48b0->opentelemetry-instrumentation-fastapi>=0.41b0->chromadb) (71.0.4)\n",
            "Requirement already satisfied: wrapt<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-instrumentation==0.48b0->opentelemetry-instrumentation-fastapi>=0.41b0->chromadb) (1.16.0)\n",
            "Requirement already satisfied: asgiref~=3.0 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-instrumentation-asgi==0.48b0->opentelemetry-instrumentation-fastapi>=0.41b0->chromadb) (3.8.1)\n",
            "Requirement already satisfied: monotonic>=1.5 in /usr/local/lib/python3.10/dist-packages (from posthog>=2.4.0->chromadb) (1.6)\n",
            "Requirement already satisfied: backoff>=1.10.0 in /usr/local/lib/python3.10/dist-packages (from posthog>=2.4.0->chromadb) (2.2.1)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic>=1.9->chromadb) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.23.4 in /usr/local/lib/python3.10/dist-packages (from pydantic>=1.9->chromadb) (2.23.4)\n",
            "Requirement already satisfied: python-dotenv>=0.21.0 in /usr/local/lib/python3.10/dist-packages (from pydantic-settings<3.0.0,>=2.4.0->langchain_community) (1.0.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (3.3.2)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->chromadb) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->chromadb) (2.18.0)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy<3,>=1.4->langchain) (3.1.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in /usr/local/lib/python3.10/dist-packages (from tokenizers>=0.13.2->chromadb) (0.24.7)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from typer>=0.9.0->chromadb) (8.1.7)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from typer>=0.9.0->chromadb) (1.5.4)\n",
            "Requirement already satisfied: httptools>=0.5.0 in /usr/local/lib/python3.10/dist-packages (from uvicorn[standard]>=0.18.3->chromadb) (0.6.1)\n",
            "Requirement already satisfied: uvloop!=0.15.0,!=0.15.1,>=0.14.0 in /usr/local/lib/python3.10/dist-packages (from uvicorn[standard]>=0.18.3->chromadb) (0.20.0)\n",
            "Requirement already satisfied: watchfiles>=0.13 in /usr/local/lib/python3.10/dist-packages (from uvicorn[standard]>=0.18.3->chromadb) (0.24.0)\n",
            "Requirement already satisfied: websockets>=10.4 in /usr/local/lib/python3.10/dist-packages (from uvicorn[standard]>=0.18.3->chromadb) (13.1)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (5.5.0)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (0.4.1)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (4.9)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers>=0.13.2->chromadb) (3.16.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers>=0.13.2->chromadb) (2024.6.1)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.10/dist-packages (from importlib-metadata<=8.4.0,>=6.0->opentelemetry-api>=1.2.0->chromadb) (3.20.2)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.10/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.4.0,>=0.3.10->langchain) (3.0.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->chromadb) (0.1.2)\n",
            "Requirement already satisfied: mypy-extensions>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain_community) (1.0.0)\n",
            "Requirement already satisfied: humanfriendly>=9.1 in /usr/local/lib/python3.10/dist-packages (from coloredlogs->onnxruntime>=1.14.1->chromadb) (10.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->onnxruntime>=1.14.1->chromadb) (1.3.0)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (0.6.1)\n",
            "Downloading langchain_openai-0.2.2-py3-none-any.whl (49 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.7/49.7 kB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: langchain_openai\n",
            "Successfully installed langchain_openai-0.2.2\n"
          ]
        }
      ],
      "source": [
        "!pip install chromadb openai langchain langchain_openai langchain_community tiktoken"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "arnp55M71BE-",
        "outputId": "393a5cd4-3adf-4197-83f8-d27361b002fe"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Name: chromadb\n",
            "Version: 0.5.13\n",
            "Summary: Chroma.\n",
            "Home-page: https://github.com/chroma-core/chroma\n",
            "Author: \n",
            "Author-email: Jeff Huber <jeff@trychroma.com>, Anton Troynikov <anton@trychroma.com>\n",
            "License: \n",
            "Location: /usr/local/lib/python3.10/dist-packages\n",
            "Requires: bcrypt, build, chroma-hnswlib, fastapi, grpcio, httpx, importlib-resources, kubernetes, mmh3, numpy, onnxruntime, opentelemetry-api, opentelemetry-exporter-otlp-proto-grpc, opentelemetry-instrumentation-fastapi, opentelemetry-sdk, orjson, overrides, posthog, pydantic, pypika, PyYAML, rich, tenacity, tokenizers, tqdm, typer, typing-extensions, uvicorn\n",
            "Required-by: \n"
          ]
        }
      ],
      "source": [
        "!pip show chromadb"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0sHvaVos4C8M"
      },
      "source": [
        "#### **Import Libraries**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "id": "6PtEWkUEpssj"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "from langchain.vectorstores import Chroma\n",
        "from langchain_openai import OpenAIEmbeddings\n",
        "from langchain_openai import OpenAI\n",
        "from langchain.document_loaders import DirectoryLoader\n",
        "from langchain.document_loaders import TextLoader\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "from langchain.chains import RetrievalQA"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3A6TAw1D35jl"
      },
      "source": [
        "### **2. Set up OpenAI API Key**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "aJP5oafV3w9t"
      },
      "outputs": [],
      "source": [
        "os.environ['OPENAI_API_KEY'] = \"YOUR_API_KEY\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PfbxK4qF2qgl"
      },
      "source": [
        "### **3. Download Dataset**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "LPdAlY5T2eRx"
      },
      "outputs": [],
      "source": [
        "# Use wget to download a file from a specified URL\n",
        "!wget -q https://www.dropbox.com/s/vs6ocyvpzzncvwh/new_articles.zip"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "okSc5OeZVxSb"
      },
      "source": [
        "Explanation of options:\n",
        "-  -q: This option enables \"quiet\" mode, which suppresses output messages.\n",
        "-  The command will run without displaying progress or error messages.\n",
        "-  The URL points to a ZIP file hosted on Dropbox."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P2M3Z4Mp3nU-"
      },
      "source": [
        "### **4. Unzip Dataset**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "d3N2yuf_3gjL"
      },
      "outputs": [],
      "source": [
        "# Use unzip to extract files from a ZIP archive\n",
        "!unzip -q new_articles.zip -d new_articles"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GXokC7i_V3_S"
      },
      "source": [
        " Explanation of options:\n",
        "-  -q: This option enables \"quiet\" mode, which suppresses output messages\n",
        "during the extraction process.\n",
        "-  new_articles.zip: This is the name of the ZIP file to be extracted.\n",
        "-  -d new_articles: This option specifies the destination directory\n",
        "where the extracted files will be placed. In this case,\n",
        "the files will be extracted into a folder named 'new_articles'."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MfsLbL6hTuqQ"
      },
      "source": [
        "## **5. Load data**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "_BQDcjJv33Iq"
      },
      "outputs": [],
      "source": [
        "# Import the DirectoryLoader class (assuming it is already imported in your context)\n",
        "# This line initializes a DirectoryLoader instance to load text files from a specified directory\n",
        "loader = DirectoryLoader(\n",
        "    \"/content/new_articles/\",  # The path to the directory containing the text files\n",
        "    glob=\"./*.txt\",           # A glob pattern to match all .txt files in the directory\n",
        "    loader_cls=TextLoader     # The class to use for loading the text files (TextLoader)\n",
        ")\n",
        "\n",
        "# Explanation of parameters:\n",
        "# - \"/content/new_articles/\": This is the directory where the text files are located.\n",
        "# - glob=\"./*.txt\": This pattern indicates that only files with a .txt extension should be loaded.\n",
        "# - loader_cls=TextLoader: This specifies that the TextLoader class will be used to handle the loading of the text files."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "7WU6wzFWnETh"
      },
      "outputs": [],
      "source": [
        "document = loader.load()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "TZnYUnhdnN6P"
      },
      "outputs": [],
      "source": [
        "# document uncomment to watch loaded data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mAPZQ9IOpxJg"
      },
      "source": [
        "## **6. Chunking Of Data (Creating Chunks of Data)**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "X38tjl6SnQZ6"
      },
      "outputs": [],
      "source": [
        "# Initialize a RecursiveCharacterTextSplitter instance\n",
        "text_splitter = RecursiveCharacterTextSplitter(\n",
        "    chunk_size=1000,     # The maximum size of each chunk of text (in characters)\n",
        "    chunk_overlap=200    # The number of overlapping characters between consecutive chunks\n",
        ")\n",
        "\n",
        "# Split an input document into smaller chunks using the text splitter\n",
        "chunked_document = text_splitter.split_documents(document)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JAsH1VZ9rkdd"
      },
      "source": [
        "#### **Explanation:**\n",
        "\n",
        "1. **RecursiveCharacterTextSplitter Initialization**:\n",
        "   - `text_splitter`: This variable holds an instance of the `RecursiveCharacterTextSplitter` class.\n",
        "   - **Parameters**:\n",
        "     - `chunk_size=1000`: This specifies that each chunk of text should ideally contain up to 1000 characters.\n",
        "     - `chunk_overlap=200`: This indicates that each consecutive chunk will overlap by 200 characters. This overlap can help maintain context between chunks when processing or analyzing the text.\n",
        "\n",
        "2. **Splitting the Document**:\n",
        "   - `chunked_document`: This variable stores the output of the `split_documents` method, which is called on the `text_splitter` instance.\n",
        "   - `document`: This is the input text that you want to split into smaller chunks. The method will process this text and return a list of chunks based on the specified size and overlap."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-W9cBWn1rGey"
      },
      "source": [
        "#### **Let's Check First Chunk**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oHL0uVQorKi8",
        "outputId": "5e9f67cd-b53c-411d-dde9-725d444a721c"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Document(metadata={'source': '/content/new_articles/05-04-slack-updates-aim-to-put-ai-at-the-center-of-the-user-experience.txt'}, page_content='Slack has evolved from a pure communications platform to one that enables companies to link directly to enterprise applications without having to resort to dreaded task switching. Today, at the Salesforce World Tour event in NYC, the company announced the next step in its platform’s evolution where it will be putting AI at the forefront of the user experience, making it easier to get information and build workflows.\\n\\nIt’s important to note that these are announcements, and many of these features are not available yet.\\n\\nRob Seaman says that rather than slapping on an AI cover, they are working to incorporate it in a variety of ways across the platform. That started last month with a small step, a partnership with OpenAI to bring a ChatGPT app into Slack, the first piece of a much broader vision for AI on the platform. That part is in beta at the moment.')"
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "chunked_document[0]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_I6oSgTMq5r8"
      },
      "source": [
        "#### **Check Length of chunked_document**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "boBJV9QWqOJ0",
        "outputId": "88c2614e-9474-448a-caf2-9f8285c4c1d7"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "233"
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(chunked_document)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7l5xR8FLshLT"
      },
      "source": [
        "## **7. Creating Embeddings of chunked_document**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lxS2kZunsxMN",
        "outputId": "8633d765-4059-4bc4-ba3b-c9ff5bff92de"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "OpenAIEmbeddings(client=<openai.resources.embeddings.Embeddings object at 0x7fac9d86ef80>, async_client=<openai.resources.embeddings.AsyncEmbeddings object at 0x7fac957f0f10>, model='text-embedding-ada-002', dimensions=None, deployment='text-embedding-ada-002', openai_api_version=None, openai_api_base=None, openai_api_type=None, openai_proxy=None, embedding_ctx_length=8191, openai_api_key=SecretStr('**********'), openai_organization=None, allowed_special=None, disallowed_special=None, chunk_size=1000, max_retries=2, request_timeout=None, headers=None, tiktoken_enabled=True, tiktoken_model_name=None, show_progress_bar=False, model_kwargs={}, skip_empty=False, default_headers=None, default_query=None, retry_min_seconds=4, retry_max_seconds=20, http_client=None, http_async_client=None, check_embedding_ctx_length=True)"
            ]
          },
          "execution_count": 32,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "embedding = OpenAIEmbeddings()\n",
        "embedding"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h5UviCZ8r9CJ"
      },
      "source": [
        "## **8. Creating Local Vector Database**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "YwKTm0H_rDI4"
      },
      "outputs": [],
      "source": [
        "# Define a variable to specify the directory where data will be persisted (saved)\n",
        "persist_directory = \"db\"\n",
        "\n",
        "# Explanation:\n",
        "# - persist_directory: This variable holds the name of the directory (\"db\")\n",
        "#   that will be used for storing persistent data, such as database files,\n",
        "#   configuration files, or any other relevant data that needs to be saved\n",
        "#   for future use."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "4QSDjiqFx1XU"
      },
      "outputs": [],
      "source": [
        "# Create a vector database instance using Chroma\n",
        "vectordb = Chroma.from_documents(\n",
        "    documents=chunked_document,             # The chunked_document documents to be added to the vector database\n",
        "    embedding=embedding,        # The embedding model used to convert documents into vector representations\n",
        "    persist_directory=persist_directory  # The directory where the vector database will be stored persistently\n",
        ")\n",
        "\n",
        "# Explanation of parameters:\n",
        "# - documents=chunked_document: This argument specifies the input documents (chunked_document)\n",
        "#   that will be processed and stored in the vector database.\n",
        "# - embedding=embedding: This argument refers to the embedding model that\n",
        "#   will transform the documents into vectors, allowing for efficient\n",
        "#   similarity searches and retrieval.\n",
        "# - persist_directory=persist_directory: This indicates where the\n",
        "#   vector database will be saved, making it possible to retrieve the data\n",
        "#   later without needing to recreate it."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e43ijkyM0ZqO",
        "outputId": "3ff02fa2-84ab-44cb-927b-77514422edd7"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-34-e84f21a103c4>:2: LangChainDeprecationWarning: Since Chroma 0.4.x the manual persistence method is no longer supported as docs are automatically persisted.\n",
            "  vectordb.persist()\n"
          ]
        }
      ],
      "source": [
        "# Save the current state of the vector database to the specified directory\n",
        "vectordb.persist()\n",
        "\n",
        "# Release the reference to the vector database instance\n",
        "vectordb = None\n",
        "\n",
        "# Explanation:\n",
        "# - vectordb.persist(): This method call ensures that all changes made to the\n",
        "#   vector database are saved to the disk. This is important for data\n",
        "#   integrity, ensuring that the database can be reloaded later with the\n",
        "#   same state.\n",
        "# - vectordb = None: This line sets the variable `vectordb` to None,\n",
        "#   effectively releasing the reference to the vector database instance.\n",
        "#   This can help free up memory and indicate that the vector database is no\n",
        "#   longer in use in the current context."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-CF_OIkd29Wu"
      },
      "source": [
        "## **9. Load the Vector Database**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a0ZgIizx2b-3",
        "outputId": "1cd5d7e1-b4dc-4ea8-bd08-f4a228c563d2"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-35-595799c83c6c>:2: LangChainDeprecationWarning: The class `Chroma` was deprecated in LangChain 0.2.9 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-chroma package and should be used instead. To use it run `pip install -U :class:`~langchain-chroma` and import as `from :class:`~langchain_chroma import Chroma``.\n",
            "  vectordb = Chroma(\n"
          ]
        }
      ],
      "source": [
        "# Initialize a new instance of the Chroma vector database\n",
        "vectordb = Chroma(\n",
        "    persist_directory=persist_directory,  # The directory where the vector database will be stored persistently\n",
        "    embedding_function=embedding           # The function used to convert documents into vector representations\n",
        ")\n",
        "\n",
        "# Explanation of parameters:\n",
        "# - persist_directory=persist_directory: This argument specifies the location\n",
        "#   (set by the variable `persist_directory`) where the vector database will\n",
        "#   save its data, allowing for retrieval in future sessions.\n",
        "# - embedding_function=embedding: This argument indicates the embedding function\n",
        "#   that will be applied to documents to create their vector representations.\n",
        "#   This is essential for enabling operations like similarity searches within the database."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u1MgpVBz3fwY"
      },
      "source": [
        "## **10. Retrive the Data from Vector Database**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "id": "m35qTfrq3Wj-"
      },
      "outputs": [],
      "source": [
        "# Create a retriever instance from the vector database\n",
        "retriever = vectordb.as_retriever()\n",
        "\n",
        "# Explanation:\n",
        "# - vectordb.as_retriever(): This method converts the vector database instance\n",
        "#   (`vectordb`) into a retriever object. A retriever is designed to efficiently\n",
        "#   fetch relevant documents or data points from the vector database based on\n",
        "#   similarity search or other retrieval mechanisms.\n",
        "# - retriever: This variable will hold the retriever instance, which can be\n",
        "#   used later to query the vector database for information based on input\n",
        "#   queries or vectors."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "g3AEikCE445x",
        "outputId": "9748075f-c294-4b91-976b-fa1bd04e2bdd"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'similarity'"
            ]
          },
          "execution_count": 41,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "retriever.search_type"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pUzSGiVx34X6",
        "outputId": "b65d9d2a-8162-4a29-c00c-d8dd7643e4e4"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-37-86c957743034>:2: LangChainDeprecationWarning: The method `BaseRetriever.get_relevant_documents` was deprecated in langchain-core 0.1.46 and will be removed in 1.0. Use :meth:`~invoke` instead.\n",
            "  docs = retriever.get_relevant_documents(\"How much money did Microsoft raise?\")\n"
          ]
        }
      ],
      "source": [
        "# Retrieve relevant documents from the vector database based on a query\n",
        "docs = retriever.get_relevant_documents(\"How much money did Microsoft raise?\")\n",
        "\n",
        "# Explanation:\n",
        "# - retriever.get_relevant_documents(): This method queries the vector database\n",
        "#   using the provided string as input.\n",
        "# - \"How much money did Microsoft raise?\": This is the query for which relevant\n",
        "#   documents are being sought. The retriever will search the database for\n",
        "#   documents that are most similar or relevant to this question.\n",
        "# - docs: This variable will store the list of documents returned by the\n",
        "#   retriever that are deemed relevant to the query. These documents can be\n",
        "#   used for further processing or analysis."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z5OuMi_l4vkK",
        "outputId": "a33f3883-d0b6-4dbd-a1c6-6b5571e16bcb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Document(metadata={'source': '/content/new_articles/05-03-chatgpt-everything-you-need-to-know-about-the-ai-powered-chatbot.txt'}, page_content='April 28, 2023\\n\\nVC firms including Sequoia Capital, Andreessen Horowitz, Thrive and K2 Global are picking up new shares, according to documents seen by TechCrunch. A source tells us Founders Fund is also investing. Altogether the VCs have put in just over $300 million at a valuation of $27 billion to $29 billion. This is separate to a big investment from Microsoft announced earlier this year, a person familiar with the development told TechCrunch, which closed in January. The size of Microsoft’s investment is believed to be around $10 billion, a figure we confirmed with our source.\\n\\nApril 25, 2023\\n\\nCalled ChatGPT Business, OpenAI describes the forthcoming offering as “for professionals who need more control over their data as well as enterprises seeking to manage their end users.”'), Document(metadata={'source': '/content/new_articles/05-03-checks-the-ai-powered-data-protection-project-incubated-in-area-120-officially-exits-to-google.txt'}, page_content='The amount that Google invested in the project was never disclosed, nor was the valuation of the exit to the parent company from the incubator, but the company has confirmed that there was a valuation and that it had grown since launch.\\n\\nThe company is not disclosing how many customers it has in total but notes that they are in the sectors of gaming, health, finance, education and retail. A sampling includes Miniclip, Rovio, Kongregate, Crayola and Yousician and in total the number of customers represented by its customers is over 3 billion.\\n\\nChecks will sit in the Developer X division. “What Fergus, Nia, and the entire Google Checks team have accomplished is one of the hardest things to do. Their focus on customer needs and nimble execution has served them well, and we’re eager to push ahead in this next phase of Checks,” said Jeanine Banks in a statement.'), Document(metadata={'source': '/content/new_articles/05-07-3one4-capital-driven-by-contrarian-bets-raises-200-million-new-fund.txt'}, page_content='Partners of 3one4 Capital, a venture capital firm in India, recently went on a road show to raise a new fund. Within two and a half months, at the height of the worsening global economy, they had secured $200 million. It’s the fourth marquee fund for the Bengaluru-headquartered fund, whose portfolio includes four unicorn startups.\\n\\nThe fund, sixth overall for 3one4 Capital, was oversubscribed to $250 million but the firm is accepting only $200 million to keep itself lean and disciplined, said Pranav Pai, co-founder and partner at 3one4 Capital. The firm’s decision to limit the fund size is emblematic of its strategic choices, which have set it apart from other Indian venture firms.'), Document(metadata={'source': '/content/new_articles/05-07-fintech-space-continues-to-be-competitive-and-drama-filled.txt'}, page_content='Exclusive: Former Venmo COO raises $20M for Vera Equity\\n\\nTarabut Gateway raises $32 million to expand Saudi open banking\\n\\nMusic financing startup Duetti raises $32 million to buy old songs\\n\\nBilling platform Inbox Health raises $22.5M and more digital health fundings\\n\\nGoogle’s VC firm just led a $12 million Series A investment in Range, a startup that’s training AI to give financial advice\\n\\nOpenEnvoy raises $15 million to grow AP automation solution\\n\\nMiami-based startup Kiddie Kredit raises $1.4M with support from Dwyane Wade and Baron Davis\\n\\nBlack-owned tech firm Greenwood acquires digital banking rival. TechCrunch covered Greenwood’s last raise in March of 2021 here.')]\n"
          ]
        }
      ],
      "source": [
        "print(docs)\n",
        "\n",
        "# Explanation:\n",
        "# - print(docs): This line outputs the list of relevant documents to the console\n",
        "#   or standard output."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ao7wLBqY4Sl0",
        "outputId": "217eae29-a1ae-468e-cc3a-c533540fa1eb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "page_content='April 28, 2023\n",
            "\n",
            "VC firms including Sequoia Capital, Andreessen Horowitz, Thrive and K2 Global are picking up new shares, according to documents seen by TechCrunch. A source tells us Founders Fund is also investing. Altogether the VCs have put in just over $300 million at a valuation of $27 billion to $29 billion. This is separate to a big investment from Microsoft announced earlier this year, a person familiar with the development told TechCrunch, which closed in January. The size of Microsoft’s investment is believed to be around $10 billion, a figure we confirmed with our source.\n",
            "\n",
            "April 25, 2023\n",
            "\n",
            "Called ChatGPT Business, OpenAI describes the forthcoming offering as “for professionals who need more control over their data as well as enterprises seeking to manage their end users.”' metadata={'source': '/content/new_articles/05-03-chatgpt-everything-you-need-to-know-about-the-ai-powered-chatbot.txt'}\n"
          ]
        }
      ],
      "source": [
        "# Print the first document retrieved from the list of relevant documents\n",
        "print(docs[0])\n",
        "\n",
        "# Explanation:\n",
        "# - docs[0]: This accesses the first document in the list of relevant documents\n",
        "#   stored in the variable `docs`.\n",
        "#   It is assumed that `docs` contains multiple documents, and the first one\n",
        "#   is selected for display.\n",
        "# - print(): This function outputs the content of the first document to the\n",
        "#   console or standard output, allowing the user to see the retrieved\n",
        "#   information related to the query."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JSTQcymz6Ebh"
      },
      "source": [
        "## **11. Define Retrival Chain**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {
        "id": "3ZvA3Swg4cOU"
      },
      "outputs": [],
      "source": [
        "llm = OpenAI()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {
        "id": "UtdZ3sLu60qL"
      },
      "outputs": [],
      "source": [
        "# Create a question-answering chain using a retriever and a language model\n",
        "qa_chain = RetrievalQA.from_chain_type(\n",
        "    llm=OpenAI(),                    # Instantiate the OpenAI language model to be used for generating answers\n",
        "    chain_type=\"stuff\",              # Specify the type of chain to be used; \"stuff\" indicates a method of combining documents\n",
        "    retriever=retriever,             # Pass the retriever instance that will fetch relevant documents based on queries\n",
        "    return_source_documents=True      # Indicate that the source documents used to generate the answer should also be returned\n",
        ")\n",
        "\n",
        "# Explanation of parameters:\n",
        "# - llm=OpenAI(): This initializes the language model that will be used to process\n",
        "#   the retrieved documents and generate answers to the questions.\n",
        "# - chain_type=\"stuff\": This specifies the method by which the retrieved documents\n",
        "#   will be combined for answering. The \"stuff\" type usually implies a straightforward\n",
        "#   concatenation of documents.\n",
        "# - retriever=retriever: This argument connects the QA chain to the retriever\n",
        "#   that will supply the relevant documents needed to answer the user's queries.\n",
        "# - return_source_documents=True: This option ensures that the documents used\n",
        "#   to construct the answer are also returned, which can be useful for reference\n",
        "#   or verification."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "metadata": {
        "id": "cqYCSLxS7gu3"
      },
      "outputs": [],
      "source": [
        "# Define a function to process the response from the language model\n",
        "def process_llm_response(llm_response):\n",
        "    # Print the main result or answer from the language model's response\n",
        "    print(llm_response['result'])\n",
        "\n",
        "    # Print a header for the sources section\n",
        "    print('\\n\\nSources:')\n",
        "\n",
        "    # Iterate over each source document in the response\n",
        "    for source in llm_response[\"source_documents\"]:\n",
        "        # Print the source information from the metadata of each document\n",
        "        print(source.metadata['source'])\n",
        "\n",
        "# Explanation:\n",
        "# - llm_response: This parameter is expected to be a dictionary containing\n",
        "#   the response from the language model, including the result and source documents.\n",
        "# - print(llm_response['result']): This line retrieves and prints the main\n",
        "#   result or answer generated by the language model.\n",
        "# - print('\\n\\nSources:'): This line outputs a header to indicate the beginning\n",
        "#   of the sources section, providing clarity to the user.\n",
        "# - for source in llm_response[\"source_documents\"]: This loop iterates over\n",
        "#   the list of source documents contained in the response.\n",
        "# - print(source.metadata['source']): This line retrieves and prints the\n",
        "#   source information from the metadata of each document, which can help\n",
        "#   users trace back the information or verify its origin."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5vr5DtTV8vmB",
        "outputId": "5a670c13-7838-4202-dc61-8dfbbc6773e4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Microsoft raised $10 billion.\n",
            "\n",
            "\n",
            "Sources:\n",
            "/content/new_articles/05-03-chatgpt-everything-you-need-to-know-about-the-ai-powered-chatbot.txt\n",
            "/content/new_articles/05-03-checks-the-ai-powered-data-protection-project-incubated-in-area-120-officially-exits-to-google.txt\n",
            "/content/new_articles/05-07-3one4-capital-driven-by-contrarian-bets-raises-200-million-new-fund.txt\n",
            "/content/new_articles/05-07-fintech-space-continues-to-be-competitive-and-drama-filled.txt\n"
          ]
        }
      ],
      "source": [
        "# Define the query to be asked to the question-answering chain\n",
        "query = \"How much money did Microsoft raise?\"\n",
        "\n",
        "# Execute the question-answering chain with the specified query\n",
        "llm_response = qa_chain(query)\n",
        "\n",
        "# Process and display the response from the language model\n",
        "process_llm_response(llm_response)\n",
        "\n",
        "# Explanation:\n",
        "# - query: This variable holds the string representing the question we want\n",
        "#   to ask the language model through the QA chain.\n",
        "# - llm_response = qa_chain(query): This line calls the `qa_chain` with the\n",
        "#   specified query, which processes the question, retrieves relevant documents,\n",
        "#   and generates an answer. The result is stored in the variable `llm_response`.\n",
        "# - process_llm_response(llm_response): This function call takes the response\n",
        "#   from the language model and processes it, displaying the answer and the\n",
        "#   sources of information used to generate that answer."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hx09WVO49ptj",
        "outputId": "e99cf0c1-fe7d-42c0-b3b3-d3a28af07695"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " Pando, a startup developing fulfillment management technologies, has raised $30 million in funding and plans to use the capital to expand its global sales, marketing, and delivery capabilities. The company also plans to explore strategic partnerships and acquisitions. Pando's platform offers customizable tools and apps, as well as no-code capabilities, and uses algorithms and machine learning for supply chain predictions. The company faces competition from other vendors such as Altana and Everstream.\n",
            "\n",
            "\n",
            "Sources:\n",
            "/content/new_articles/05-03-ai-powered-supply-chain-startup-pando-lands-30m-investment.txt\n",
            "/content/new_articles/05-03-ai-powered-supply-chain-startup-pando-lands-30m-investment.txt\n",
            "/content/new_articles/05-03-ai-powered-supply-chain-startup-pando-lands-30m-investment.txt\n",
            "/content/new_articles/05-03-ai-powered-supply-chain-startup-pando-lands-30m-investment.txt\n"
          ]
        }
      ],
      "source": [
        "query = \"What is the news about Pando?\"\n",
        "llm_response = qa_chain(query)\n",
        "process_llm_response(llm_response)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NHWfLCDy-Mga"
      },
      "source": [
        "## **12. Delete the Database**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j_tai-qx-CqU",
        "outputId": "c006084f-004d-4551-978c-7c3bdd59a35e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  adding: db/ (stored 0%)\n",
            "  adding: db/chroma.sqlite3 (deflated 45%)\n",
            "  adding: db/3f24a27f-909d-4e42-8fe3-a43da163cc17/ (stored 0%)\n",
            "  adding: db/3f24a27f-909d-4e42-8fe3-a43da163cc17/data_level0.bin (deflated 100%)\n",
            "  adding: db/3f24a27f-909d-4e42-8fe3-a43da163cc17/header.bin (deflated 61%)\n",
            "  adding: db/3f24a27f-909d-4e42-8fe3-a43da163cc17/length.bin (deflated 88%)\n",
            "  adding: db/3f24a27f-909d-4e42-8fe3-a43da163cc17/link_lists.bin (stored 0%)\n"
          ]
        }
      ],
      "source": [
        "# Create a ZIP archive of the specified directory\n",
        "!zip -r db.zip ./db\n",
        "\n",
        "# Explanation of options:\n",
        "# - zip: This command is used to create a ZIP archive.\n",
        "# - -r: This option stands for \"recursive,\" meaning that all files and\n",
        "#       subdirectories within the specified directory will be included in\n",
        "#       the ZIP archive.\n",
        "# - db.zip: This is the name of the resulting ZIP file that will be created.\n",
        "#           It will contain the contents of the specified directory.\n",
        "# - ./db: This specifies the directory to be compressed into the ZIP file.\n",
        "#         In this case, it is the `db` directory located in the current working directory."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "metadata": {
        "id": "gfmr7J_t-i4n"
      },
      "outputs": [],
      "source": [
        "# Clean up resources by deleting the vector database collection\n",
        "vectordb.delete_collection()  # Remove the entire collection from the vector database\n",
        "\n",
        "# Persist any changes made before deletion\n",
        "vectordb.persist()  # Save the current state to ensure data integrity\n",
        "\n",
        "# Delete the associated directory from the file system\n",
        "!rm -rf db/  # Remove the 'db' directory and all its contents forcefully and recursively\n",
        "\n",
        "# Explanation:\n",
        "# - vectordb.delete_collection(): This method call deletes the collection\n",
        "#   within the vector database, freeing up resources and clearing stored data.\n",
        "# - vectordb.persist(): This ensures that any changes made to the database\n",
        "#   are saved before deletion, which is important for ensuring that\n",
        "#   modifications are not lost.\n",
        "# - !rm -rf db/: This command uses the `rm` utility to remove the `db`\n",
        "#   directory. The options `-r` and `-f` stand for recursive and force,\n",
        "#   respectively, meaning that all files and subdirectories in `db` will be\n",
        "#   deleted without prompting for confirmation."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 62,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dvRDCF5n-1QI",
        "outputId": "603d66d4-1d3e-492e-992f-f9c9e4bcc2da"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Archive:  db.zip\n",
            "   creating: db/\n",
            "  inflating: db/chroma.sqlite3       \n",
            "   creating: db/3f24a27f-909d-4e42-8fe3-a43da163cc17/\n",
            "  inflating: db/3f24a27f-909d-4e42-8fe3-a43da163cc17/data_level0.bin  \n",
            "  inflating: db/3f24a27f-909d-4e42-8fe3-a43da163cc17/header.bin  \n",
            "  inflating: db/3f24a27f-909d-4e42-8fe3-a43da163cc17/length.bin  \n",
            " extracting: db/3f24a27f-909d-4e42-8fe3-a43da163cc17/link_lists.bin  \n"
          ]
        }
      ],
      "source": [
        "# Extract the contents of the ZIP archive\n",
        "!unzip db.zip\n",
        "\n",
        "# Explanation:\n",
        "# - !unzip: This command is used to extract files from a ZIP archive.\n",
        "# - db.zip: This specifies the name of the ZIP file to be extracted.\n",
        "#   The contents of this file will be unpacked into the current working directory."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mlGWX1DI_drQ"
      },
      "source": [
        "-------------------\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cqvCFGJu_etB"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
